{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning: Cycle Share\n",
    "\n",
    "There are 3 datasets that provide data on the stations, trips, and weather from 2014-2016.\n",
    "\n",
    "**Station dataset**\n",
    "\n",
    "* station_id: station ID number\n",
    "* name: name of station\n",
    "* lat: station latitude\n",
    "* long: station longitude\n",
    "* install_date: date that station was placed in service\n",
    "* install_dockcount: number of docks at each station on the installation date\n",
    "* modification_date: date that station was modified, resulting in a change in location or dock count\n",
    "* current_dockcount: number of docks at each station on 8/31/2016\n",
    "* decommission_date: date that station was placed out of service\n",
    "\n",
    "**Trip dataset**\n",
    "\n",
    "* trip_id: numeric ID of bike trip taken\n",
    "* starttime: day and time trip started, in PST\n",
    "* stoptime: day and time trip ended, in PST\n",
    "* bikeid: ID attached to each bike\n",
    "* tripduration: time of trip in seconds\n",
    "* from_station_name: name of station where trip originated\n",
    "* to_station_name: name of station where trip terminated\n",
    "* from_station_id: ID of station where trip originated\n",
    "* to_station_id: ID of station where trip terminated\n",
    "* usertype: \"Short-Term Pass Holder\" is a rider who purchased a 24-Hour or 3-Day Pass; \"Member\" is a rider who purchased a Monthly or an Annual Membership\n",
    "* gender: gender of rider\n",
    "* birthyear: birth year of rider\n",
    "\n",
    "**Weather dataset** contains daily weather information in the service area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard data science modules\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Import listdir module for finding files to load\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import all sets into a dictionary and correct any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File : trip.csv\n",
      "\n",
      "Error tokenizing data. C error: Expected 12 fields in line 50794, saw 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read all data files from cycle_share folder\n",
    "files = listdir('cycle_share')\n",
    "\n",
    "# Iterate through file names, load data to a dictionary\n",
    "data = {}\n",
    "for f in files:\n",
    "    k = f.split('.')[0]  # remove .csv\n",
    "    path = 'cycle_share/' + f\n",
    "    try:\n",
    "        data[k] = pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print('File : {}\\n'.format(f))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59000,\"4/17/2015 14:21\",\"4/17/2015 19:21\",\"SEA00362\",17990.668,\"6th Ave S & S King St\",\"Westlake Ave & 6th Ave\",\"ID-04\",\"SLU-15\"trip_id\",\"starttime\",\"stoptime\",\"bikeid\",\"tripduration\",\"from_station_name\",\"to_station_name\",\"from_station_id\",\"to_station_id\",\"usertype\",\"gender\",\"birthyear\"\n",
      " \n",
      "\n",
      "431,\"10/13/2014 10:31\",\"10/13/2014 10:48\",\"SEA00298\",985.935,\"2nd Ave & Spring St\",\"Occidental Park / Occidental Ave S & S Washington St\",\"CBD-06\",\"PS-04\",\"Member\",\"Male\",1960\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Error in line 50794 (index 50793): compare to another line to view differences\n",
    "with open('cycle_share/trip.csv') as f:\n",
    "    lines = f.readlines()\n",
    "for l in lines[50793:50795]:\n",
    "    print(l, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns are detected in line 50793 vs 50794?\n",
    "len(lines[50793].split(',')), len(lines[50794].split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like column names are attached to the end of the 'offending row'. Examine at the first line in the file to see if column names are also at the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"trip_id\"',\n",
       " '\"starttime\"',\n",
       " '\"stoptime\"',\n",
       " '\"bikeid\"',\n",
       " '\"tripduration\"',\n",
       " '\"from_station_name\"',\n",
       " '\"to_station_name\"',\n",
       " '\"from_station_id\"',\n",
       " '\"to_station_id\"',\n",
       " '\"usertype\"',\n",
       " '\"gender\"',\n",
       " '\"birthyear\"\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print tokens for column names\n",
    "lines[0].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So we just have some odd problem where column names also ended up mashed into the middle of our file**\n",
    "Let's correct the problem in the offending line, and re-save the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['59000',\n",
       " '\"4/17/2015 14:21\"',\n",
       " '\"4/17/2015 19:21\"',\n",
       " '\"SEA00362\"',\n",
       " '17990.668',\n",
       " '\"6th Ave S & S King St\"',\n",
       " '\"Westlake Ave & 6th Ave\"',\n",
       " '\"ID-04\"',\n",
       " '\"SLU-15\"trip_id\"',\n",
       " '\"starttime\"',\n",
       " '\"stoptime\"',\n",
       " '\"bikeid\"',\n",
       " '\"tripduration\"',\n",
       " '\"from_station_name\"',\n",
       " '\"to_station_name\"',\n",
       " '\"from_station_id\"',\n",
       " '\"to_station_id\"',\n",
       " '\"usertype\"',\n",
       " '\"gender\"',\n",
       " '\"birthyear\"\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify bad line and tokenize\n",
    "bad_line = lines[50793]\n",
    "bad_tokens = bad_line.split(',')\n",
    "bad_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `bad_tokens`, nothing is valid beyond \"SLU-15\" (the `to_station_id`). Solution: consider remaining values as null, inserting nothing between commas to denote that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['59000',\n",
       " '\"4/17/2015 14:21\"',\n",
       " '\"4/17/2015 19:21\"',\n",
       " '\"SEA00362\"',\n",
       " '17990.668',\n",
       " '\"6th Ave S & S King St\"',\n",
       " '\"Westlake Ave & 6th Ave\"',\n",
       " '\"ID-04\"',\n",
       " '\"SLU-15\"trip_id\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = bad_tokens[:9]\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct 'trip_id' at the end of new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"SLU-15\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the \"trip_id\" at the end\n",
    "end = new_tokens[-1]\n",
    "end = '\"' + end.split('\"')[1] + '\"'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'59000,\"4/17/2015 14:21\",\"4/17/2015 19:21\",\"SEA00362\",17990.668,\"6th Ave S & S King St\",\"Westlake Ave & 6th Ave\",\"ID-04\",\"SLU-15\",,,\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens[-1] = end\n",
    "new_tokens.append(2*',' + '\\n')\n",
    "new_line = ','.join(new_tokens)\n",
    "new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length (should be 12)\n",
    "len(new_line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace bad line with new one\n",
    "lines[50793] = new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write lines to new file to correct error\n",
    "with open('cycle_share/trip_fixed.csv','w') as f:\n",
    "    for l in lines:\n",
    "        f.write(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try reading files in again\n",
    "(Skipping the origin trip.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear data dictionary, iterate through file names and load data to a dictionary\n",
    "data = {}\n",
    "for f in files:\n",
    "    # we want to load trip_fixed, not trip\n",
    "    if f != 'trip.csv':\n",
    "        k = f.split('.')[0]  # remove .csv\n",
    "        path = 'cycle_share/' + f\n",
    "        try:\n",
    "            # change key for dict\n",
    "            if k == 'trip_fixed':\n",
    "                k = 'trip'\n",
    "            data[k] = pd.read_csv(path)\n",
    "        except Exception as e:\n",
    "            print('File : {}\\n'.format(f))\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Print data summaries including the number of null values. Should we drop or try to correct any of the null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION \n",
      "\n",
      "Null counts\n",
      "station_id            0\n",
      "name                  0\n",
      "lat                   0\n",
      "long                  0\n",
      "install_date          0\n",
      "install_dockcount     0\n",
      "modification_date    41\n",
      "current_dockcount     0\n",
      "decommission_date    54\n",
      "dtype: int64 \n",
      "\n",
      "                   count        mean       std         min         25%  \\\n",
      "lat                 58.0   47.624796  0.019066   47.598488   47.613239   \n",
      "long                58.0 -122.327242  0.014957 -122.355230 -122.338735   \n",
      "install_dockcount   58.0   17.586207  3.060985   12.000000   16.000000   \n",
      "current_dockcount   58.0   16.517241  5.117021    0.000000   16.000000   \n",
      "\n",
      "                          50%         75%         max  \n",
      "lat                 47.618591   47.627712   47.666145  \n",
      "long              -122.328207 -122.316691 -122.284119  \n",
      "install_dockcount   18.000000   18.000000   30.000000  \n",
      "current_dockcount   18.000000   18.000000   26.000000   \n",
      "\n",
      "                  count unique                    top freq\n",
      "station_id           58     58                 CBD-13    1\n",
      "name                 58     58  6th Ave S & S King St    1\n",
      "install_date         58      9             10/13/2014   50\n",
      "modification_date    17     12              2/20/2015    4\n",
      "decommission_date     4      4               7/2/2016    1 \n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "TRIP_CLEANED \n",
      "\n",
      "Null counts\n",
      "trip_id                            0\n",
      "starttime                          0\n",
      "stoptime                           0\n",
      "bikeid                             0\n",
      "tripduration                       0\n",
      "from_station_name                  0\n",
      "to_station_name                    0\n",
      "from_station_id                    0\n",
      "to_station_id                      0\n",
      "usertype                           0\n",
      "gender                         89894\n",
      "birthyear                      89898\n",
      "Max_Temperature_F                  0\n",
      "Mean_Temperature_F                 0\n",
      "Min_TemperatureF                   0\n",
      "Max_Dew_Point_F                    0\n",
      "MeanDew_Point_F                    0\n",
      "Min_Dewpoint_F                     0\n",
      "Max_Humidity                       0\n",
      "Mean_Humidity                      0\n",
      "Min_Humidity                       0\n",
      "Max_Sea_Level_Pressure_In          0\n",
      "Mean_Sea_Level_Pressure_In         0\n",
      "Min_Sea_Level_Pressure_In          0\n",
      "Max_Visibility_Miles               0\n",
      "Mean_Visibility_Miles              0\n",
      "Min_Visibility_Miles               0\n",
      "Max_Wind_Speed_MPH                 0\n",
      "Mean_Wind_Speed_MPH                0\n",
      "Max_Gust_Speed_MPH            236065\n",
      "Precipitation_In                   0\n",
      "Events                        150239\n",
      "from_lat                           5\n",
      "from_lon                           5\n",
      "to_lat                            20\n",
      "to_long                           20\n",
      "dtype: int64 \n",
      "\n",
      "                               count           mean           std  \\\n",
      "trip_id                     236065.0  130059.869333  72842.289278   \n",
      "tripduration                236065.0    1202.612410   2066.424721   \n",
      "birthyear                   146167.0    1979.879740     10.154978   \n",
      "Max_Temperature_F           236065.0      68.438879     12.184481   \n",
      "Mean_Temperature_F          236065.0      60.092987     10.089620   \n",
      "Min_TemperatureF            236065.0      52.185606      9.038677   \n",
      "Max_Dew_Point_F             236065.0      50.037384      6.896901   \n",
      "MeanDew_Point_F             236065.0      46.634579      7.286060   \n",
      "Min_Dewpoint_F              236065.0      42.455430      8.348857   \n",
      "Max_Humidity                236065.0      82.000763      9.813263   \n",
      "Mean_Humidity               236065.0      64.610476     12.550082   \n",
      "Min_Humidity                236065.0      45.345545     15.019366   \n",
      "Max_Sea_Level_Pressure_In   236065.0      30.116351      0.161908   \n",
      "Mean_Sea_Level_Pressure_In  236065.0      30.041776      0.168290   \n",
      "Min_Sea_Level_Pressure_In   236065.0      29.958614      0.184384   \n",
      "Max_Visibility_Miles        236065.0       9.996827      0.148997   \n",
      "Mean_Visibility_Miles       236065.0       9.622540      0.961409   \n",
      "Min_Visibility_Miles        236065.0       7.940830      3.035578   \n",
      "Max_Wind_Speed_MPH          236065.0      10.626793      3.321629   \n",
      "Mean_Wind_Speed_MPH         236065.0       4.300582      2.433723   \n",
      "Max_Gust_Speed_MPH               0.0            NaN           NaN   \n",
      "Precipitation_In            236065.0       0.058296      0.159728   \n",
      "from_lat                    236060.0      47.620419      0.014335   \n",
      "from_lon                    236060.0    -122.330959      0.013894   \n",
      "to_lat                      236045.0      47.619727      0.015255   \n",
      "to_long                     236045.0    -122.333187      0.012957   \n",
      "\n",
      "                                    min           25%            50%  \\\n",
      "trip_id                      431.000000  67746.000000  130526.000000   \n",
      "tripduration                  60.000000    392.500000     633.000000   \n",
      "birthyear                   1931.000000   1975.000000    1983.000000   \n",
      "Max_Temperature_F             39.000000     59.000000      68.000000   \n",
      "Mean_Temperature_F            33.000000     52.000000      60.000000   \n",
      "Min_TemperatureF              23.000000     46.000000      54.000000   \n",
      "Max_Dew_Point_F               10.000000     46.000000      51.000000   \n",
      "MeanDew_Point_F                4.000000     43.000000      48.000000   \n",
      "Min_Dewpoint_F                 1.000000     38.000000      44.000000   \n",
      "Max_Humidity                  40.000000     75.000000      83.000000   \n",
      "Mean_Humidity                 24.000000     56.000000      65.000000   \n",
      "Min_Humidity                  15.000000     34.000000      44.000000   \n",
      "Max_Sea_Level_Pressure_In     29.470000     30.010000      30.100000   \n",
      "Mean_Sea_Level_Pressure_In    29.310000     29.940000      30.040000   \n",
      "Min_Sea_Level_Pressure_In     29.140000     29.870000      29.970000   \n",
      "Max_Visibility_Miles           3.000000     10.000000      10.000000   \n",
      "Mean_Visibility_Miles          1.000000     10.000000      10.000000   \n",
      "Min_Visibility_Miles           0.000000      6.000000      10.000000   \n",
      "Max_Wind_Speed_MPH             4.000000      8.000000      10.000000   \n",
      "Mean_Wind_Speed_MPH            0.000000      3.000000       4.000000   \n",
      "Max_Gust_Speed_MPH                  NaN           NaN            NaN   \n",
      "Precipitation_In               0.000000      0.000000       0.000000   \n",
      "from_lat                      47.598488     47.613628      47.618285   \n",
      "from_lon                    -122.355230   -122.339641    -122.332447   \n",
      "to_lat                        47.598488     47.610185      47.615829   \n",
      "to_long                     -122.355230   -122.341102    -122.335768   \n",
      "\n",
      "                                      75%            max  \n",
      "trip_id                     192900.000000  255245.000000  \n",
      "tripduration                  1145.000000   28794.500000  \n",
      "birthyear                     1987.000000    1999.000000  \n",
      "Max_Temperature_F               78.000000      98.000000  \n",
      "Mean_Temperature_F              68.000000      83.000000  \n",
      "Min_TemperatureF                59.000000      70.000000  \n",
      "Max_Dew_Point_F                 55.000000      77.000000  \n",
      "MeanDew_Point_F                 52.000000      59.000000  \n",
      "Min_Dewpoint_F                  48.000000      57.000000  \n",
      "Max_Humidity                    89.000000     100.000000  \n",
      "Mean_Humidity                   74.000000      95.000000  \n",
      "Min_Humidity                    57.000000      87.000000  \n",
      "Max_Sea_Level_Pressure_In       30.220000      30.860000  \n",
      "Mean_Sea_Level_Pressure_In      30.140000      30.810000  \n",
      "Min_Sea_Level_Pressure_In       30.070000      30.750000  \n",
      "Max_Visibility_Miles            10.000000      10.000000  \n",
      "Mean_Visibility_Miles           10.000000      10.000000  \n",
      "Min_Visibility_Miles            10.000000      10.000000  \n",
      "Max_Wind_Speed_MPH              12.000000      30.000000  \n",
      "Mean_Wind_Speed_MPH              6.000000      23.000000  \n",
      "Max_Gust_Speed_MPH                    NaN            NaN  \n",
      "Precipitation_In                 0.020000       2.200000  \n",
      "from_lat                        47.623165      47.666145  \n",
      "from_lon                      -122.321251    -122.284119  \n",
      "to_lat                          47.623165      47.666145  \n",
      "to_long                       -122.326412    -122.284119   \n",
      "\n",
      "                    count  unique                              top    freq\n",
      "starttime          236065  176216              2016-07-10 12:37:00      11\n",
      "stoptime           236065  169285              2016-04-16 17:16:00      12\n",
      "bikeid             236065     493                         SEA00281     667\n",
      "from_station_name  236065      61  Pier 69 / Alaskan Way & Clay St   11274\n",
      "to_station_name    236065      61  Pier 69 / Alaskan Way & Clay St   11768\n",
      "from_station_id    236065      61                            WF-01   11274\n",
      "to_station_id      236065      61                            WF-01   11768\n",
      "usertype           236065       2                           Member  146171\n",
      "gender             146171       3                             Male  112940\n",
      "Events              85826       9                             Rain   74888 \n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "TRIP \n",
      "\n",
      "Null counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_id                   0\n",
      "starttime                 0\n",
      "stoptime                  0\n",
      "bikeid                    0\n",
      "tripduration              0\n",
      "from_station_name         0\n",
      "to_station_name           0\n",
      "from_station_id           0\n",
      "to_station_id             0\n",
      "usertype                  1\n",
      "gender               105301\n",
      "birthyear            105305\n",
      "dtype: int64 \n",
      "\n",
      "                 count           mean           std       min          25%  \\\n",
      "trip_id       286858.0  112431.781746  76565.086482   431.000  43051.00000   \n",
      "tripduration  286858.0    1178.354284   2038.697070    60.008    387.92575   \n",
      "birthyear     181553.0    1979.759062     10.167119  1931.000   1974.00000   \n",
      "\n",
      "                      50%           75%         max  \n",
      "trip_id       103486.5000  179544.75000  255245.000  \n",
      "tripduration     624.8465    1118.48325   28794.398  \n",
      "birthyear       1983.0000    1987.00000    1999.000   \n",
      "\n",
      "                    count  unique                              top    freq\n",
      "starttime          286858  176216                 10/13/2014 11:51      18\n",
      "stoptime           286858  169285                 10/13/2014 11:51      18\n",
      "bikeid             286858     493                         SEA00281     835\n",
      "from_station_name  286858      61  Pier 69 / Alaskan Way & Clay St   13054\n",
      "to_station_name    286858      61                2nd Ave & Pine St   13784\n",
      "from_station_id    286858      61                            WF-01   13054\n",
      "to_station_id      286858      61                           CBD-13   13784\n",
      "usertype           286857       2                           Member  181557\n",
      "gender             181557       3                             Male  140564 \n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "WEATHER \n",
      "\n",
      "Null counts\n",
      "Date                            0\n",
      "Max_Temperature_F               0\n",
      "Mean_Temperature_F              1\n",
      "Min_TemperatureF                0\n",
      "Max_Dew_Point_F                 0\n",
      "MeanDew_Point_F                 0\n",
      "Min_Dewpoint_F                  0\n",
      "Max_Humidity                    0\n",
      "Mean_Humidity                   0\n",
      "Min_Humidity                    0\n",
      "Max_Sea_Level_Pressure_In       0\n",
      "Mean_Sea_Level_Pressure_In      0\n",
      "Min_Sea_Level_Pressure_In       0\n",
      "Max_Visibility_Miles            0\n",
      "Mean_Visibility_Miles           0\n",
      "Min_Visibility_Miles            0\n",
      "Max_Wind_Speed_MPH              0\n",
      "Mean_Wind_Speed_MPH             0\n",
      "Max_Gust_Speed_MPH            185\n",
      "Precipitation_In                0\n",
      "Events                        361\n",
      "dtype: int64 \n",
      "\n",
      "                            count       mean        std    min    25%    50%  \\\n",
      "Max_Temperature_F           689.0  64.027576  12.427843  39.00  55.00  63.00   \n",
      "Mean_Temperature_F          688.0  56.584302  10.408058  33.00  48.00  56.00   \n",
      "Min_TemperatureF            689.0  49.454282   9.451437  23.00  43.00  50.00   \n",
      "Max_Dew_Point_F             689.0  48.571843   7.501230  10.00  44.00  50.00   \n",
      "MeanDew_Point_F             689.0  45.021771   7.914025   4.00  41.00  46.00   \n",
      "Min_Dewpoint_F              689.0  40.873730   8.854608   1.00  36.00  42.00   \n",
      "Max_Humidity                689.0  84.541364   9.718948  40.00  78.00  86.00   \n",
      "Mean_Humidity               689.0  68.506531  12.701871  24.00  60.00  70.00   \n",
      "Min_Humidity                689.0  49.973875  15.825701  15.00  38.00  50.00   \n",
      "Max_Sea_Level_Pressure_In   689.0  30.121742   0.183367  29.47  30.01  30.12   \n",
      "Mean_Sea_Level_Pressure_In  689.0  30.034761   0.197503  29.31  29.93  30.04   \n",
      "Min_Sea_Level_Pressure_In   689.0  29.940610   0.221803  29.14  29.84  29.96   \n",
      "Max_Visibility_Miles        689.0   9.989840   0.266679   3.00  10.00  10.00   \n",
      "Mean_Visibility_Miles       689.0   9.429608   1.174360   1.00   9.00  10.00   \n",
      "Min_Visibility_Miles        689.0   7.245283   3.281278   0.00   4.00   9.00   \n",
      "Max_Wind_Speed_MPH          689.0  11.085631   3.921087   4.00   8.00  10.00   \n",
      "Mean_Wind_Speed_MPH         689.0   4.631350   2.780320   0.00   3.00   4.00   \n",
      "Precipitation_In            689.0   0.105065   0.235644   0.00   0.00   0.00   \n",
      "\n",
      "                              75%     max  \n",
      "Max_Temperature_F           73.00   98.00  \n",
      "Mean_Temperature_F          65.00   83.00  \n",
      "Min_TemperatureF            57.00   70.00  \n",
      "Max_Dew_Point_F             54.00   77.00  \n",
      "MeanDew_Point_F             51.00   59.00  \n",
      "Min_Dewpoint_F              47.00   57.00  \n",
      "Max_Humidity                90.00  100.00  \n",
      "Mean_Humidity               79.00   95.00  \n",
      "Min_Humidity                63.00   87.00  \n",
      "Max_Sea_Level_Pressure_In   30.24   30.86  \n",
      "Mean_Sea_Level_Pressure_In  30.16   30.81  \n",
      "Min_Sea_Level_Pressure_In   30.08   30.75  \n",
      "Max_Visibility_Miles        10.00   10.00  \n",
      "Mean_Visibility_Miles       10.00   10.00  \n",
      "Min_Visibility_Miles        10.00   10.00  \n",
      "Max_Wind_Speed_MPH          13.00   30.00  \n",
      "Mean_Wind_Speed_MPH          6.00   23.00  \n",
      "Precipitation_In             0.09    2.20   \n",
      "\n",
      "                   count unique        top freq\n",
      "Date                 689    689  11/6/2015    1\n",
      "Max_Gust_Speed_MPH   504     25          -  225\n",
      "Events               328      9       Rain  287 \n",
      "\n",
      " -------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through data dictionary\n",
    "for k in data.keys():\n",
    "    # print data name\n",
    "    print(k.upper(), '\\n')\n",
    "    \n",
    "    # show null couts\n",
    "    print('Null counts')\n",
    "    print(data[k].isnull().sum(), '\\n')\n",
    "    \n",
    "    # summaries for columns of numeric type\n",
    "    print(data[k].describe().T, '\\n')\n",
    "    # summaries for columns of 'object' type\n",
    "    \n",
    "    print(data[k].describe(include=['O']).T, '\\n\\n', 50*'-', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the null values in the data are critical for analysis. While there is not a sensible way to impute `modification_date` from the existing information, `Mean_temperature_F` can be reasonably be imputed as the mean of the two days bracketing the null value. This is because it is unlikely for mean temperatures to vary drastically from one day to the next, although this reasoning will not work for extended stretches of null values where there is more likely to be a shift in mean temperature. There is no reason to drop any missing values from the data from the information we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['weather'].Mean_Temperature_F.fillna(method = 'ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a column in the trip table that contains only the date (no time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10/13/2014 10:31'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is present in the current date value?\n",
    "data['trip'].starttime[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# date and time are separated by a space, so split each accordingly using list comprehension\n",
    "data['trip']['date'] = [t.split(' ')[0] for t in data['trip'].starttime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10/13/2014\n",
       "1    10/13/2014\n",
       "2    10/13/2014\n",
       "3    10/13/2014\n",
       "4    10/13/2014\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 dates\n",
    "data['trip'].date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge weather data with trip data and be sure not to lose any trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a left join will preserve all trip data and leave dates with no weather (if any) as null\n",
    "trip_weather = data['trip'].merge(data['weather'], left_on = 'date', right_on = 'Date', how = 'left')\n",
    "\n",
    "# now drop the unnecessary date/Date columns\n",
    "trip_weather.drop(['date','Date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trip_weather) == len(data['trip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drop records that are completely duplicated (all values). Check for and inspect any duplicate trip_id values that remain. Remove if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286858, 32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check starting shape of 'trip_weather' data\n",
    "trip_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236066, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates and reset index\n",
    "trip_weather.drop_duplicates(inplace = True)\n",
    "trip_weather.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# check size of resulting data\n",
    "trip_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of duplicated trip IDs\n",
    "dup_mask = trip_weather.trip_id.duplicated()\n",
    "dup_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50792</th>\n",
       "      <th>50793</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trip_id</th>\n",
       "      <td>59000</td>\n",
       "      <td>59000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttime</th>\n",
       "      <td>4/17/2015 14:21</td>\n",
       "      <td>4/17/2015 14:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoptime</th>\n",
       "      <td>4/17/2015 19:21</td>\n",
       "      <td>4/17/2015 19:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bikeid</th>\n",
       "      <td>SEA00362</td>\n",
       "      <td>SEA00362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripduration</th>\n",
       "      <td>17990.7</td>\n",
       "      <td>17990.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_station_name</th>\n",
       "      <td>6th Ave S &amp; S King St</td>\n",
       "      <td>6th Ave S &amp; S King St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_station_name</th>\n",
       "      <td>Westlake Ave &amp; 6th Ave</td>\n",
       "      <td>Westlake Ave &amp; 6th Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_station_id</th>\n",
       "      <td>ID-04</td>\n",
       "      <td>ID-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_station_id</th>\n",
       "      <td>SLU-15</td>\n",
       "      <td>SLU-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usertype</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Short-Term Pass Holder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birthyear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Temperature_F</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Temperature_F</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_TemperatureF</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Dew_Point_F</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanDew_Point_F</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Dewpoint_F</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Humidity</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Humidity</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Humidity</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Sea_Level_Pressure_In</th>\n",
       "      <td>30.32</td>\n",
       "      <td>30.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Sea_Level_Pressure_In</th>\n",
       "      <td>30.25</td>\n",
       "      <td>30.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Sea_Level_Pressure_In</th>\n",
       "      <td>30.22</td>\n",
       "      <td>30.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Visibility_Miles</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Visibility_Miles</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Visibility_Miles</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Wind_Speed_MPH</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Wind_Speed_MPH</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Gust_Speed_MPH</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation_In</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Events</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             50792                   50793\n",
       "trip_id                                      59000                   59000\n",
       "starttime                          4/17/2015 14:21         4/17/2015 14:21\n",
       "stoptime                           4/17/2015 19:21         4/17/2015 19:21\n",
       "bikeid                                    SEA00362                SEA00362\n",
       "tripduration                               17990.7                 17990.7\n",
       "from_station_name            6th Ave S & S King St   6th Ave S & S King St\n",
       "to_station_name             Westlake Ave & 6th Ave  Westlake Ave & 6th Ave\n",
       "from_station_id                              ID-04                   ID-04\n",
       "to_station_id                               SLU-15                  SLU-15\n",
       "usertype                                       NaN  Short-Term Pass Holder\n",
       "gender                                         NaN                     NaN\n",
       "birthyear                                      NaN                     NaN\n",
       "Max_Temperature_F                               68                      68\n",
       "Mean_Temperature_F                              56                      56\n",
       "Min_TemperatureF                                46                      46\n",
       "Max_Dew_Point_F                                 46                      46\n",
       "MeanDew_Point_F                                 42                      42\n",
       "Min_Dewpoint_F                                  33                      33\n",
       "Max_Humidity                                    77                      77\n",
       "Mean_Humidity                                   57                      57\n",
       "Min_Humidity                                    28                      28\n",
       "Max_Sea_Level_Pressure_In                    30.32                   30.32\n",
       "Mean_Sea_Level_Pressure_In                   30.25                   30.25\n",
       "Min_Sea_Level_Pressure_In                    30.22                   30.22\n",
       "Max_Visibility_Miles                            10                      10\n",
       "Mean_Visibility_Miles                           10                      10\n",
       "Min_Visibility_Miles                            10                      10\n",
       "Max_Wind_Speed_MPH                              12                      12\n",
       "Mean_Wind_Speed_MPH                              3                       3\n",
       "Max_Gust_Speed_MPH                              21                      21\n",
       "Precipitation_In                                 0                       0\n",
       "Events                                         NaN                     NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_trip_id = trip_weather.loc[dup_mask[dup_mask == True].index].trip_id\n",
    "\n",
    "# look at data for duplicates\n",
    "trip_weather[trip_weather.trip_id.isin(dup_trip_id)].sort_values(by='trip_id').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It looks like the only difference is that one record has a value for `user_type` and the other doesn't**\n",
    "\n",
    "Drop the record without `user_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_weather.drop(50792, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create columns for lat & long values for the from- and to- stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_weather = trip_weather.merge(data['station'][['station_id','lat','long']],\n",
    "                                  left_on = 'from_station_id', right_on = 'station_id', how='left')\\\n",
    "                           .merge(data['station'][['station_id','lat','long']],\n",
    "                                  left_on = 'to_station_id', right_on = 'station_id', how = 'left')\n",
    "\n",
    "trip_weather.rename(columns = {'lat_x': 'from_lat', 'long_x': 'from_lon', 'lat_y': 'to_lat','long_y': 'to_long'},\n",
    "                    inplace = True)\n",
    "\n",
    "trip_weather.drop(['station_id_x', 'station_id_y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trip_id</th>\n",
       "      <td>431</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttime</th>\n",
       "      <td>10/13/2014 10:31</td>\n",
       "      <td>10/13/2014 10:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoptime</th>\n",
       "      <td>10/13/2014 10:48</td>\n",
       "      <td>10/13/2014 10:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bikeid</th>\n",
       "      <td>SEA00298</td>\n",
       "      <td>SEA00195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripduration</th>\n",
       "      <td>985.935</td>\n",
       "      <td>926.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_station_name</th>\n",
       "      <td>2nd Ave &amp; Spring St</td>\n",
       "      <td>2nd Ave &amp; Spring St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_station_name</th>\n",
       "      <td>Occidental Park / Occidental Ave S &amp; S Washing...</td>\n",
       "      <td>Occidental Park / Occidental Ave S &amp; S Washing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_station_id</th>\n",
       "      <td>CBD-06</td>\n",
       "      <td>CBD-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_station_id</th>\n",
       "      <td>PS-04</td>\n",
       "      <td>PS-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usertype</th>\n",
       "      <td>Member</td>\n",
       "      <td>Member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birthyear</th>\n",
       "      <td>1960</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Temperature_F</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Temperature_F</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_TemperatureF</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Dew_Point_F</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanDew_Point_F</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Dewpoint_F</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Humidity</th>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Humidity</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Humidity</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Sea_Level_Pressure_In</th>\n",
       "      <td>30.03</td>\n",
       "      <td>30.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Sea_Level_Pressure_In</th>\n",
       "      <td>29.79</td>\n",
       "      <td>29.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Sea_Level_Pressure_In</th>\n",
       "      <td>29.65</td>\n",
       "      <td>29.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Visibility_Miles</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Visibility_Miles</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_Visibility_Miles</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Wind_Speed_MPH</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Wind_Speed_MPH</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_Gust_Speed_MPH</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precipitation_In</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Events</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_lat</th>\n",
       "      <td>47.6059</td>\n",
       "      <td>47.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_lon</th>\n",
       "      <td>-122.336</td>\n",
       "      <td>-122.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_lat</th>\n",
       "      <td>47.6008</td>\n",
       "      <td>47.6008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_long</th>\n",
       "      <td>-122.333</td>\n",
       "      <td>-122.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            0  \\\n",
       "trip_id                                                                   431   \n",
       "starttime                                                    10/13/2014 10:31   \n",
       "stoptime                                                     10/13/2014 10:48   \n",
       "bikeid                                                               SEA00298   \n",
       "tripduration                                                          985.935   \n",
       "from_station_name                                         2nd Ave & Spring St   \n",
       "to_station_name             Occidental Park / Occidental Ave S & S Washing...   \n",
       "from_station_id                                                        CBD-06   \n",
       "to_station_id                                                           PS-04   \n",
       "usertype                                                               Member   \n",
       "gender                                                                   Male   \n",
       "birthyear                                                                1960   \n",
       "Max_Temperature_F                                                          71   \n",
       "Mean_Temperature_F                                                         62   \n",
       "Min_TemperatureF                                                           54   \n",
       "Max_Dew_Point_F                                                            55   \n",
       "MeanDew_Point_F                                                            51   \n",
       "Min_Dewpoint_F                                                             46   \n",
       "Max_Humidity                                                               87   \n",
       "Mean_Humidity                                                              68   \n",
       "Min_Humidity                                                               46   \n",
       "Max_Sea_Level_Pressure_In                                               30.03   \n",
       "Mean_Sea_Level_Pressure_In                                              29.79   \n",
       "Min_Sea_Level_Pressure_In                                               29.65   \n",
       "Max_Visibility_Miles                                                       10   \n",
       "Mean_Visibility_Miles                                                      10   \n",
       "Min_Visibility_Miles                                                        4   \n",
       "Max_Wind_Speed_MPH                                                         13   \n",
       "Mean_Wind_Speed_MPH                                                         4   \n",
       "Max_Gust_Speed_MPH                                                         21   \n",
       "Precipitation_In                                                            0   \n",
       "Events                                                                   Rain   \n",
       "from_lat                                                              47.6059   \n",
       "from_lon                                                             -122.336   \n",
       "to_lat                                                                47.6008   \n",
       "to_long                                                              -122.333   \n",
       "\n",
       "                                                                            1  \n",
       "trip_id                                                                   432  \n",
       "starttime                                                    10/13/2014 10:32  \n",
       "stoptime                                                     10/13/2014 10:48  \n",
       "bikeid                                                               SEA00195  \n",
       "tripduration                                                          926.375  \n",
       "from_station_name                                         2nd Ave & Spring St  \n",
       "to_station_name             Occidental Park / Occidental Ave S & S Washing...  \n",
       "from_station_id                                                        CBD-06  \n",
       "to_station_id                                                           PS-04  \n",
       "usertype                                                               Member  \n",
       "gender                                                                   Male  \n",
       "birthyear                                                                1970  \n",
       "Max_Temperature_F                                                          71  \n",
       "Mean_Temperature_F                                                         62  \n",
       "Min_TemperatureF                                                           54  \n",
       "Max_Dew_Point_F                                                            55  \n",
       "MeanDew_Point_F                                                            51  \n",
       "Min_Dewpoint_F                                                             46  \n",
       "Max_Humidity                                                               87  \n",
       "Mean_Humidity                                                              68  \n",
       "Min_Humidity                                                               46  \n",
       "Max_Sea_Level_Pressure_In                                               30.03  \n",
       "Mean_Sea_Level_Pressure_In                                              29.79  \n",
       "Min_Sea_Level_Pressure_In                                               29.65  \n",
       "Max_Visibility_Miles                                                       10  \n",
       "Mean_Visibility_Miles                                                      10  \n",
       "Min_Visibility_Miles                                                        4  \n",
       "Max_Wind_Speed_MPH                                                         13  \n",
       "Mean_Wind_Speed_MPH                                                         4  \n",
       "Max_Gust_Speed_MPH                                                         21  \n",
       "Precipitation_In                                                            0  \n",
       "Events                                                                   Rain  \n",
       "from_lat                                                              47.6059  \n",
       "from_lon                                                             -122.336  \n",
       "to_lat                                                                47.6008  \n",
       "to_long                                                              -122.333  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_weather.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Write a function to round all `tripduration` values to the nearest half second increment and then round all the values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def round_to_half(x):\n",
    "    return round(x*2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_weather['tripduration'] = trip_weather.tripduration.apply(lambda x: round_to_half(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Verify that `trip_duration` matches the timestamps to within 60 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Convert start and stop time columns to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_weather.starttime = pd.to_datetime(trip_weather.starttime)\n",
    "trip_weather.stoptime = pd.to_datetime(trip_weather.stoptime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of computed trip durations in seconds and use the math library to check if all values are within 60 seconds of eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_durations = [round_to_half((r.stoptime - r.starttime).seconds) for r in trip_weather.itertuples()]\n",
    "all([math.isclose(a,b, rel_tol=60) for a,b in zip(trip_durations, trip_weather.tripduration)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Something is wrong with the `Max_Gust_Speed_MPH` column. Identify and correct the problem, then save the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data summaries printed after the first problem shows that Max_Gust_Speed_MPH appears in the  Object type summary, not the numeric. The top value is also '`-`'. This is the cause of the problem. Change these all to Nan using `np.nan`, then change the column type to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace dash with nan\n",
    "trip_weather.Max_Gust_Speed_MPH = trip_weather.Max_Gust_Speed_MPH.apply(lambda x: x if isinstance(x, float) \n",
    "                                                                        else np.nan)\n",
    "# change column dtype to float\n",
    "trip_weather.Max_Gust_Speed_MPH = trip_weather.Max_Gust_Speed_MPH.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_weather.iloc[:, 29].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trip_weather data as trip_cleaned.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_weather.to_csv('cycle_share/trip_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning: Movies\n",
    "\n",
    "This data set contains 28 attributes related to various movie titles that have been scraped from IMDb. The set is supposed to contain unique titles for each record, where each record has the following attributes:\n",
    "\n",
    "\"movie_title\" \"color\" \"num_critic_for_reviews\" \"movie_facebook_likes\" \"duration\" \"director_name\" \"director_facebook_likes\" \"actor_3_name\" \"actor_3_facebook_likes\" \"actor_2_name\" \"actor_2_facebook_likes\" \"actor_1_name\" \"actor_1_facebook_likes\" \"gross\" \"genres\" \"num_voted_users\" \"cast_total_facebook_likes\" \"facenumber_in_poster\" \"plot_keywords\" \"movie_imdb_link\" \"num_user_for_reviews\" \"language\" \"country\" \"content_rating\" \"budget\" \"title_year\" \"imdb_score\" \"aspect_ratio\"\n",
    "\n",
    "The original set is available kaggle ([here](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import movies data\n",
    "movies = pd.read_csv('movies/movies_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5043 entries, 0 to 5042\n",
      "Data columns (total 28 columns):\n",
      "color                        5024 non-null object\n",
      "director_name                4939 non-null object\n",
      "num_critic_for_reviews       4993 non-null float64\n",
      "duration                     5028 non-null float64\n",
      "director_facebook_likes      4939 non-null float64\n",
      "actor_3_facebook_likes       5020 non-null float64\n",
      "actor_2_name                 5030 non-null object\n",
      "actor_1_facebook_likes       5036 non-null float64\n",
      "gross                        4159 non-null float64\n",
      "genres                       5043 non-null object\n",
      "actor_1_name                 5036 non-null object\n",
      "movie_title                  5043 non-null object\n",
      "num_voted_users              5043 non-null int64\n",
      "cast_total_facebook_likes    5043 non-null int64\n",
      "actor_3_name                 5020 non-null object\n",
      "facenumber_in_poster         5030 non-null float64\n",
      "plot_keywords                4890 non-null object\n",
      "movie_imdb_link              5043 non-null object\n",
      "num_user_for_reviews         5022 non-null float64\n",
      "language                     5031 non-null object\n",
      "country                      5038 non-null object\n",
      "content_rating               4740 non-null object\n",
      "budget                       4551 non-null float64\n",
      "title_year                   4935 non-null float64\n",
      "actor_2_facebook_likes       5030 non-null float64\n",
      "imdb_score                   5043 non-null float64\n",
      "aspect_ratio                 4714 non-null float64\n",
      "movie_facebook_likes         5043 non-null int64\n",
      "dtypes: float64(13), int64(3), object(12)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check for and correct similar values in `color`, `language`,  and `country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color \n",
      "\n",
      "Black and White     206\n",
      "Color              4799\n",
      "black and white       3\n",
      "color                16\n",
      "Name: color, dtype: int64 \n",
      "\n",
      "\n",
      "language \n",
      "\n",
      "Aboriginal       2\n",
      "Arabic           5\n",
      "Aramaic          1\n",
      "Bosnian          1\n",
      "Cantonese       11\n",
      "Chinese          3\n",
      "Czech            1\n",
      "Danish           5\n",
      "Dari             2\n",
      "Dutch            4\n",
      "Dzongkha         1\n",
      "English       4704\n",
      "Filipino         1\n",
      "French          73\n",
      "German          19\n",
      "Greek            1\n",
      "Hebrew           5\n",
      "Hindi           28\n",
      "Hungarian        1\n",
      "Icelandic        2\n",
      "Indonesian       2\n",
      "Italian         11\n",
      "Japanese        18\n",
      "Kannada          1\n",
      "Kazakh           1\n",
      "Korean           8\n",
      "Mandarin        26\n",
      "Maya             1\n",
      "Mongolian        1\n",
      "None             2\n",
      "Norwegian        4\n",
      "Panjabi          1\n",
      "Persian          4\n",
      "Polish           4\n",
      "Portuguese       8\n",
      "Romanian         2\n",
      "Russian         11\n",
      "Slovenian        1\n",
      "Spanish         40\n",
      "Swahili          1\n",
      "Swedish          5\n",
      "Tamil            1\n",
      "Telugu           1\n",
      "Thai             3\n",
      "Urdu             1\n",
      "Vietnamese       1\n",
      "Zulu             2\n",
      "Name: language, dtype: int64 \n",
      "\n",
      "\n",
      "country \n",
      "\n",
      "Afghanistan                1\n",
      "Argentina                  4\n",
      "Aruba                      1\n",
      "Australia                 55\n",
      "Bahamas                    1\n",
      "Belgium                    4\n",
      "Brazil                     8\n",
      "Bulgaria                   1\n",
      "Cambodia                   1\n",
      "Cameroon                   1\n",
      "Canada                   126\n",
      "Chile                      1\n",
      "China                     30\n",
      "Colombia                   1\n",
      "Czech Republic             3\n",
      "Denmark                   11\n",
      "Dominican Republic         1\n",
      "Egypt                      1\n",
      "Finland                    1\n",
      "France                   154\n",
      "Georgia                    1\n",
      "Germany                   97\n",
      "Greece                     2\n",
      "Hong Kong                 17\n",
      "Hungary                    2\n",
      "Iceland                    3\n",
      "India                     34\n",
      "Indonesia                  1\n",
      "Iran                       4\n",
      "Ireland                   12\n",
      "                        ... \n",
      "Libya                      1\n",
      "Mexico                    17\n",
      "Netherlands                5\n",
      "New Line                   1\n",
      "New Zealand               15\n",
      "Nigeria                    1\n",
      "Norway                     8\n",
      "Official site              1\n",
      "Pakistan                   1\n",
      "Panama                     1\n",
      "Peru                       1\n",
      "Philippines                1\n",
      "Poland                     5\n",
      "Romania                    4\n",
      "Russia                    11\n",
      "Slovakia                   1\n",
      "Slovenia                   1\n",
      "South Africa               8\n",
      "South Korea               14\n",
      "Soviet Union               1\n",
      "Spain                     33\n",
      "Sweden                     6\n",
      "Switzerland                3\n",
      "Taiwan                     2\n",
      "Thailand                   5\n",
      "Turkey                     1\n",
      "UK                       448\n",
      "USA                     3807\n",
      "United Arab Emirates       1\n",
      "West Germany               3\n",
      "Name: country, Length: 65, dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in ['color','language','country']:\n",
    "    print(col, '\\n')\n",
    "    print(movies[col].value_counts().sort_index(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the color column needs to be corrected. Both color categories have a few versions with the incorrect case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Color              4815\n",
       "Black and White     209\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.loc[(movies.color == 'color'), 'color'] = 'Color'\n",
    "movies.loc[(movies.color == 'black and white'), 'color'] = 'Black and White'\n",
    "movies.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a function that detects and lists non-numeric columns containing values with leading or trailing whitespace. Remove the whitespace in these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check for whitespace in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check for leading or trailing whitespace\n",
    "def has_whitespace(data, cols):\n",
    "    whitespace = []\n",
    "    for col in cols:\n",
    "        for x in data[col]:\n",
    "            # in case encounter null values that can't split\n",
    "            try:\n",
    "                l = x.split(' ')\n",
    "                if (l[0] == '') | (l[-1] == ''):\n",
    "                    # has leading or trailing whitespace\n",
    "                    print('{} has whitespace'.format(col))\n",
    "                    whitespace.append(col)\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    return whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director_name has whitespace\n",
      "actor_2_name has whitespace\n",
      "movie_title has whitespace\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['director_name', 'actor_2_name', 'movie_title']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of all non-numeric columns\n",
    "str_cols = movies.select_dtypes(include=['O']).columns\n",
    "\n",
    "# get those with whitespace\n",
    "whitespace = has_whitespace(movies, str_cols)\n",
    "whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip this space using pandas apply method and Series.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies[whitespace] = movies[whitespace].apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for whitespace again\n",
    "has_whitespace(movies, str_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove duplicate records. Inspect any remaining duplicate movie titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4998, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates and check shape\n",
    "movies.drop_duplicates(inplace = True)\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect any remaining duplicate movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4916, 4998)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare number of unique movie titles with length of the data\n",
    "movies.movie_title.nunique(), len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the duplicates titles and drop duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4916.000000\n",
       "mean        1.016680\n",
       "std         0.132763\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         3.000000\n",
       "Name: movie_title, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine stats for counts per title\n",
    "movies.movie_title.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Home', 'King Kong', 'Ben-Hur', 'Day of the Dead', 'The Host',\n",
       "       'Goosebumps', 'The Return of the Living Dead', 'Lucky Number Slevin',\n",
       "       'The Karate Kid', 'Teenage Mutant Ninja Turtles', 'Brothers', 'Heist',\n",
       "       'First Blood', 'The Jungle Book', 'Chasing Liberty', 'Jack Reacher',\n",
       "       'Ghostbusters', 'The Great Gatsby', 'Dekalog', 'The Unborn', 'Carrie',\n",
       "       'Eddie the Eagle', 'Casino Royale', 'Creepshow', 'Disturbia',\n",
       "       'Cinderella', 'Conan the Barbarian', 'The Lovers',\n",
       "       'Oz the Great and Powerful', 'The Island', 'Halloween', 'The Gift',\n",
       "       'Spider-Man 3', 'The Lovely Bones', 'The Dead Zone', 'Sabotage',\n",
       "       'Alice in Wonderland', 'Planet of the Apes', 'The Gambler',\n",
       "       'The Texas Chain Saw Massacre', 'Murder by Numbers', 'Skyfall',\n",
       "       'Lolita', 'The Tourist', 'Exodus: Gods and Kings', 'Precious',\n",
       "       'Point Break', 'Clash of the Titans', 'Glory', 'Syriana', 'RoboCop',\n",
       "       'Unknown', 'Victor Frankenstein', 'A Nightmare on Elm Street', 'Pan',\n",
       "       '20,000 Leagues Under the Sea', 'The Day the Earth Stood Still',\n",
       "       'The Last House on the Left', 'Poltergeist',\n",
       "       'Dodgeball: A True Underdog Story', 'Aloha', 'Across the Universe',\n",
       "       'Around the World in 80 Days', 'Snakes on a Plane', 'Dawn of the Dead',\n",
       "       'Twilight', 'The Fast and the Furious', 'TRON: Legacy', 'The Watch',\n",
       "       'Juno', 'The Fog', 'House of Wax', 'Mercury Rising', 'Side Effects',\n",
       "       'The Astronaut's Wife', 'Snitch', 'Dredd', 'Out of the Blue',\n",
       "       'The Omen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of titles with counts\n",
    "movie_counts = movies.movie_title.value_counts()\n",
    "\n",
    "# select titles with count > 1 (duplicates)\n",
    "potential_dups = movie_counts[movie_counts > 1].index\n",
    "potential_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a function that returns two arrays: one for titles that are truly duplicated, and  one for duplicated titles are not the same movie.\n",
    "* hint: do this by comparing the imdb link values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_duplicates(movies, potential):\n",
    "    # subset tells pandas what columns to consider when determining duplicates\n",
    "    subset=['movie_title','movie_imdb_link']\n",
    "    \n",
    "    # a boolean mask for indexing duplicated titles\n",
    "    dup_mask = movies.duplicated(subset = subset)\n",
    "    \n",
    "    # get duplicated titles\n",
    "    duplicated = movies.loc[dup_mask].movie_title.unique()\n",
    "    \n",
    "    # get the titles from mask that are not in duplicated\n",
    "    not_duplicated = Series(potential)[~Series(potential).isin(duplicated)].values\n",
    "    \n",
    "    return duplicated, not_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Host', 'The Dead Zone', 'Out of the Blue'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup, not_dup = movie_duplicates(movies, potential_dups)\n",
    "not_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alter the names of duplicate titles that are different movies so each is unique. Then drop all duplicate rows based on movie title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate through titles, renaming non-duplicate titles\n",
    "for m in not_dup:\n",
    "    # enumerate indices of titles\n",
    "    for n, idx in enumerate(movies[movies.movie_title == m].index):\n",
    "        # append '_n' to end of titles\n",
    "        movies.loc[idx, 'movie_title'] = m + '_{}'.format(n)\n",
    "\n",
    "# drop duplicate movies\n",
    "movies.drop_duplicates(subset = ['movie_title'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure there are no longer duplicate titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alexander's Ragtime Band             1\n",
       "Beverly Hills Chihuahua              1\n",
       "Supernova                            1\n",
       "Iron Man 3                           1\n",
       "A Thin Line Between Love and Hate    1\n",
       "Name: movie_title, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of titles with counts\n",
    "movies.movie_title.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create a series that ranks actors by proportion of movies they have appeared in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get value counts for actors in each of the actor columns\n",
    "a1 = DF(movies.actor_1_name.value_counts())\n",
    "a2 = DF(movies.actor_2_name.value_counts())\n",
    "a3 = DF(movies.actor_3_name.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge all of these using an outer join (not all actors in all 3 columns, want to keep all)\n",
    "a_all = a1.merge(a2, how='outer', left_index = True, right_index = True)\\\n",
    "    .merge(a3, how='outer', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Robert De Niro    0.010775\n",
       "Morgan Freeman    0.008742\n",
       "Bruce Willis      0.007725\n",
       "Matt Damon        0.007522\n",
       "Johnny Depp       0.007319\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum across axis 1 to get the total for each actor\n",
    "actor_counts = a_all.sum(axis = 1)\n",
    "\n",
    "# create the ranks by dividing each actor total by total number of movies\n",
    "actor_ranks = (actor_counts/len(movies)).sort_values(ascending = False)\n",
    "actor_ranks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create a table that contains the first and last years each actor appeared, and their length of history. Then include columns for the actors proportion and total number of movies.\n",
    "* length is number of years they have appeared in movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor_1_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50 Cent</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Buckley</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaliyah</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aasif Mandvi</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abbie Cornish</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first    last\n",
       "actor_1_name                 \n",
       "50 Cent        2005.0  2005.0\n",
       "A.J. Buckley   2015.0  2015.0\n",
       "Aaliyah        2002.0  2002.0\n",
       "Aasif Mandvi   2008.0  2008.0\n",
       "Abbie Cornish  2009.0  2012.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create group objects for each actor column\n",
    "g1 = movies.groupby('actor_1_name')\n",
    "g2 = movies.groupby('actor_2_name')\n",
    "g3 = movies.groupby('actor_3_name')\n",
    "\n",
    "\n",
    "# use apply method to get dataframes with first and last years for each actor\n",
    "hists = {}\n",
    "for i,g in enumerate([g1, g2, g3]):\n",
    "    k = 'g{}'.format(i)\n",
    "    hists[k] = g.apply(lambda x: Series({'last': x['title_year'].max(),\n",
    "                                         'first': x['title_year'].min()}))\n",
    "\n",
    "# preview results\n",
    "hists['g0'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge all history tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Laurence Olivier</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debbie Reynolds</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlon Brando</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dean Stockwell</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert Duvall</th>\n",
       "      <td>1962.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   first    last  years\n",
       "Laurence Olivier  1940.0  2004.0   64.0\n",
       "Debbie Reynolds   1952.0  2012.0   60.0\n",
       "Marlon Brando     1951.0  2006.0   55.0\n",
       "Dean Stockwell    1947.0  2001.0   54.0\n",
       "Robert Duvall     1962.0  2014.0   52.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = hists['g0'].merge(hists['g1'], how='outer', left_index = True, right_index = True) \\\n",
    "    .merge(hists['g2'], how='outer', left_index = True, right_index = True)\n",
    "\n",
    "# compute years from max - min of each row\n",
    "actor_hist = history.apply(lambda r: Series({'first': r.min(),\n",
    "                                       'last':r.max(),\n",
    "                                       'years': r.max() - r.min()}),\n",
    "                    axis=1).sort_values(by='years', ascending = False)\n",
    "\n",
    "# preview results\n",
    "actor_hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns for number and proportion of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>years</th>\n",
       "      <th>movie_prop</th>\n",
       "      <th>movie_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Laurence Olivier</th>\n",
       "      <td>1940.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debbie Reynolds</th>\n",
       "      <td>1952.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlon Brando</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dean Stockwell</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert Duvall</th>\n",
       "      <td>1962.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   first    last  years  movie_prop  movie_count\n",
       "Laurence Olivier  1940.0  2004.0   64.0    0.001016          5.0\n",
       "Debbie Reynolds   1952.0  2012.0   60.0    0.000813          4.0\n",
       "Marlon Brando     1951.0  2006.0   55.0    0.001830          9.0\n",
       "Dean Stockwell    1947.0  2001.0   54.0    0.001016          5.0\n",
       "Robert Duvall     1962.0  2014.0   52.0    0.004879         24.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_hist['movie_prop'] = actor_ranks\n",
    "actor_hist['movie_count'] = round(actor_ranks*len(movies))\n",
    "actor_hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create a column that gives each movie an integer ranking based on gross sales\n",
    "* 1 should indicate the highest gross\n",
    "* If more than one movie has equal sales, assign all the lowest rank in the group\n",
    "* The next rank after this group should increase only by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using pandas `rank` method, setting ascending to false (highest sales gets rank 1), and using `method='dense'`.\n",
    "\n",
    "This last part is what ensures not only does a group of titles sharing equal sales get the same rank (smallest in group), but it also tells the ranking to increase the next higher number by only one, instead of that rank being group rank + number in group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies['movie_sales_rank'] = movies.gross.rank(method = 'min', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gross</th>\n",
       "      <th>movie_sales_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760505847.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>658672302.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>652177271.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>623279547.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>533316061.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>474544677.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>460935665.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>458991599.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>448130642.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>436471036.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gross  movie_sales_rank\n",
       "0     760505847.0               1.0\n",
       "26    658672302.0               2.0\n",
       "29    652177271.0               3.0\n",
       "17    623279547.0               4.0\n",
       "66    533316061.0               5.0\n",
       "240   474544677.0               6.0\n",
       "3024  460935665.0               7.0\n",
       "8     458991599.0               8.0\n",
       "3     448130642.0               9.0\n",
       "582   436471036.0              10.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice the inverse relation between rank and gross\n",
    "movies[['gross', 'movie_sales_rank']].sort_values(by = 'gross', ascending = False).head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
